---
title: 推荐系统1
subtitle: 推荐系统概述
layout: post
author: 陈家辉
tags:
- 架构设计
- 推荐系统
---

# 什么是推荐系统？

维基百科定义：它是一种信息过滤系统，手段是预测**用户**对**物品**的评分和偏好。

**它能做什么**

推荐系统可以把那些最终会在用户和物品之间产生的连接提前找出来。

所谓的连接其实是一个很广阔的概念，人的一切属性和其他物品的属性能够进行关联都称之为连接。

1. 世界的发展趋势是万物倾向于建⽴立越来越多的连接;
2. 人是这一切趋势的意义所在，为人建⽴连接是要义;
3. 根据已有的连接预测和⼈有关的连接，就是推荐系统。

**它需要什么**

需要收集大量的数据，这些数据可以称之为已有的连接，根据已有的连接推测将会发生的连接。

**怎么做**

实现方式分为两类：机器推荐，人工推荐。

机器推荐又可分为个性化推荐，以及网红推荐（如何将网红推给对应人群，这是我们需要去实现的）

简而言之：推荐系统就是用已有的连接去预测未来用户和物品之间会出现的连接。（这里的物品也可以表示人）

# 是否需要推荐系统？

1. 产品的目的不在于建立连接，例如工具类产品。
2. 产品目前的体量，如果产品中的物品很少，那么采用人工推荐可能是更好的选择。

组建一套推荐系统，需要不小的前期投入，包括组建团队，购置计算资源，积累数据，花费时间优化，当系统体量较小时，我们更需要考虑的是用户增长问题。有一个判断标准，$\triangle connection/(\triangle user *\triangle item)$

当该系数扩大的时候，表明我们系统的连接数在发生自增长，那么就可以考虑加入推荐系统。当然这只是数据层面来说，出于其他战略考虑的话，也是可以加入推荐系统。

# 推荐系统的问题模式

## 评分预测

例如一个用户消费完一个物品，会给物品打分。那么评分预测就是把用户可能回答高分的物品推给用户，让用户进行消费。

那么如何去建立模型呢，有一个朴素的方法，就是对用户曾经打分的商品进行打分，然后将预测分值和实际分值进行比较，得出误差，根据误差去调整模型参数，让这个误差越来越小。这就是机器学习里面的回归问题。

对模型的准确率评判使用RMSE，即均方根误差。

$RMSE = \sqrt{\frac{\sum_{i=1}^{n}(y_i - \hat{y_i})^2}{n}}
$

$\hat{y_i}$表示预测分值，$y_i$表示实际分值。

评分预测问题常见于各种点评类产品，例如书影音评分。但是评分类推荐存在以下问题，

1. 数据不易收集，评分往往产生在最后一步，数据量相对较少
2. 数据质量无法保证，用户可能是随手点了个评分，同时人的评分标准不统一

## 行为预测

行为预测与评分不同，用户在APP上会进行大量的行为操作，可以根据这些数据对用户接下来的行为进行预测。

## 常见的问题

推荐系统有几个常见的问题，并没有很好的通用解决方案。

1. 冷启动问题
2. 探索与利用问题
3. 安全问题

**冷启动问题**

推荐系统是数据贪婪型应用，所谓贪婪型应用就是对数据需求是无限大。系统初期，缺乏对应的数据，想让系统启动起来就很困难。

**探索与利用问题（EE问题）**

假设我们已经知道了用户的喜好，一般有三种对待方式：

1. 全部给他推荐感兴趣的物品
2. 无视他的兴趣，按其他逻辑给他推荐，如编辑推荐、随机推荐、按时间先后推荐等等
3. 大部分给他推荐感兴趣的，小部分去试探新的兴趣

第三种方式明显更为科学，那么如何平衡这两个部分，这就是EE问题的核心，Exploit意为开采，explore意为探索。

# 用户画像

## 什么是用户画像

用户画像即User profile，原本用于营销领域，传统营销领域，画像系统会为用户打各种标签，市场销售人员可以根据各种标签对客户定制化服务。

然而推荐系统的用户画像和上述的传统画像有着很大的区别，根本原因就在于我们的用户画像是给机器看，而不是给人看。

首先推荐系统需要将用户和物品向量化，这样才能进行计算。不同的算法，向量化的方式也不同，最终对匹配评分方法也不同。

用户向量化后的结果，即为用户画像，用户画像是构建推荐系统的过程中产生的一个副产品。

另外通常大型推荐系统一般都分为召回和排序两个阶段。由于全量物品数量非常大，无法为一个用户逐一计算每一个物品的评分，这时候就需要召回，即预筛选掉一部分物品，从而降低计算量。最后再根据评分做排序。

## 关键因素

举个简单的例子，例如店铺推荐，我们可以将店铺向量化，暂定向量的维度有：

1. 价格，1~5分，1分最贵
2. 种类，1~5分，1分代表最少
3. 质量，1~5分，1分表示最差

那么我们会对用户也进行上述的评分，如果一个用户不差钱，只看中质量，该用户的向量可能如下所示

> 1:1
>
> 2:3
>
> 3:5

呢么我们可以简单的计算，将每个维度相乘累加，就可以得到每个店铺的分值，根据分值进行排序即可。

从上面这个例子我们可以看出，构建画像，首先要定义维度，其次是对个维度进行量化。

## 构建画像

### 构建方法

主要分为三类构建方法。

**查户口**

直接使用原始数据构建用户画像，如注册资料，人口统计学信息，购买历史，阅读历史等，一般用于冷启动场景。相对而言不需要什么技术含量，主要就是数据清洗，不会对数据做任何抽象和归纳。

**堆数据**

通过统计来堆积历史数据，最常见的就是兴趣标签，从历史的行为数据中挖掘标签，然后在标签维度上做数据统计，用统计结果作为量化结果。

**黑盒**

使用机器学习方法，形成稠密向量，在推荐系统中承担主要作用。

比如使用浅语义模型构建用户阅读兴趣，或者使用矩阵分解得到的隐因子，或者使用深度学习模型学习用户的Embedding向量。

### 从文本构建

文本是互联网中最常见的信息载体，用户拥有姓名，个人签名，评论动态，点赞，聊天记录等等一系列信息可以用于构建用户画像。物品这边有标题描述，各种属性。

当然文本面临的问题在于，数据结构不统一，信息冗余量大等一系列问题，一般来说文本构建画像分为以下两步

1. 文本结构化，提取关键信息
2. 根据用户行为提取出物品结构化结果，将用户信息与物品信息合并

#### **文本结构化**

由于我们的文本数据，一般来说都是自然语言，即非结构化数据。我们需要将这些数据处理成结构化的数据索引，然后进行向量化计算。

可以试用NLP算法分析文本，得到以下数据：

1. 关键词提取：为其他文本分析提供基础数据，常用TF-IDF和TextRank
2. 实体识别：人物、位置和地点、著作影视剧、历史事件和热点事件等，常用基于词典的方法结合CRF模型
3. 内容分类：将文本按照分类体系分类，用分类来表达较粗粒度的结构化信息
4. 文本：无监督学习，将文本划分为多个类簇
5. 主题模型：从大量的已有文本中学习主题向量，然后预测新的文本在各个主题上的概率分布情况，也很实用。
6. 嵌入：嵌入表达用于挖掘字面下的义信息，并且使用有限的维度进行表达

##### TF-IDF

TF全称为Term Frequency，IDF就是Inverse Document Frequency。该算法的思想很简单，主要包括两点：在一篇文字中反复出现的词会更重要，在所有文本中都出现的词更不重要。

TF：关键词在目标文本中出现的次数

IDF：提前统计好，在现有的文本中，每一个词出现在多少个文本中记为n，也就是文档频率，记为n，也就是文档频率，一共有多少文本，记为N，$IDF=log\frac{N}{n+1}$。

对于IDF而言，N是固定的，n越小，IDF越大。为了防止n为0导致的IDF无穷大，我们需要对分母+1。

计算出TF和IDF后，将两值相乘，就得到每一个词的权重，根据权重可以取topk也可以自定义过滤。

##### TextRank

TextRank和PageRank的思路类似。

1. 设定一个窗口宽度，比如取k个词，统计窗口内的词的共现关系，将其看成无向图
2. 所有词初始化的重要性都是1
3. 每个节点把自己的权重平均分给和自己有链接的其他节点
4. 每个节点将其他节点分给自己的权重求和，作为该节点的新权重
5. 反复迭代3、4步，直接节点权重收敛

这样有共现关系的词会互相支持对方成为关键词。

##### 内容分类

在门户网站时代，每个门户都有自己的频道体系，这就是内容分类体系的一种。如今是UGC时代，文本相对都比较短，短文本提取经典的算法是SVM，常见的工具则是Facebook的FastText。

##### 实体识别

命名实体识别（Named-Entity Recognition）是序列标注问题，和分词、词性标注属于同类问题。

序列标注问题，就是给你一个字符序列，从左向右遍历每个字符，并且对每个字符进行分类，分类的体系因序列标注问题不同有所差异。

1. 分词问题：将每一个字符分类为词开始，词中间，词结束。
2. 词性标注：对每一个分好的词，分类为定义的词性集合之一。
3. 实体识别：对每一个分好的词，识别为定义好的实体集合之一

通常的算法就是隐马尔科夫模型HMM或者条件随机场CRF。

非模型算法有：词典法，提前定义好词典，如果在词典中找到这个词，就能找到对应的实体。

常见的工具有spaCy和NLTK。

##### 聚类

传统聚类方法在文本中的运用，今天逐渐被主题模型取代，以LDA为代表的主题模型可以更准确的抓住主题，同时能够得到软聚类的效果，让一条文本属于多个类簇。

LDA难点在于并行化，如果文本数量没有达到海量，可以考虑提高单机配置，开源的LDA训练工具有Gensim，PLDA。

##### 词嵌入

为一个词学习得到一个稠密的向量，例如北京，可以包含首都、中国、北方、直辖市等语义，假设有128个语义，那么我们可以用一个128维向量来表达，各个维度的大小则表示在这个维度上的语义多少。

我们可以通过这个向量

1. 计算词相似度，扩充结构化标签
2. 累加得到一个文本的稠密向量
3. 用于聚类，会得到比使用词向量聚类更好的语义聚类效果

这方面的权威做法就是Word2Vec，通过浅层神经网络学习得到每个词的向量表达，Word2Vec在工程技巧上进行了优化，百万规模再单机上可以轻松地计算出向量。

#### 标签选择

前面我们已经可以将用户和物品的信息进行结构化，那么如何从这些结构化信息中提取中我们想要的信息呢？

一种简单粗暴的办法就是直接把用户产生过行为的物品标签累积在一起。最常见的两个方法就是卡方检验CHI和信息增益IG。

1. 把物品的结构化内容看成文档
2. 把用户对物品的行为看成是类别
3. 每个用户看见过的物品是一个文本集合
4. 在这个文本集合上使用特征选择算法选出每个用户关心的东西

# 内容推荐

内容推荐，实际上就是一个包装成推荐系统的信息检索系统。

抓：抓取数据，丰富自己的内容

洗：清洗数据

挖：挖掘数据

算：匹配用户的兴趣和物品的属性，计算出更合理的相关性

内容推荐，最重要的不是推荐算法，而是内容挖掘和分析。