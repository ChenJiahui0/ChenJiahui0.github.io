---
title: 推荐系统1
subtitle: 推荐系统概述
publish: false
layout: post
author: 陈家辉
tags:
- 架构设计
- 推荐系统
---

# 什么是推荐系统？

维基百科定义：它是一种信息过滤系统，手段是预测**用户**对**物品**的评分和偏好。

**它能做什么**

推荐系统可以把那些最终会在用户和物品之间产生的连接提前找出来。

所谓的连接其实是一个很广阔的概念，人的一切属性和其他物品的属性能够进行关联都称之为连接。

1. 世界的发展趋势是万物倾向于建⽴立越来越多的连接;
2. 人是这一切趋势的意义所在，为人建⽴连接是要义;
3. 根据已有的连接预测和⼈有关的连接，就是推荐系统。

**它需要什么**

需要收集大量的数据，这些数据可以称之为已有的连接，根据已有的连接推测将会发生的连接。

**怎么做**

实现方式分为两类：机器推荐，人工推荐。

机器推荐又可分为个性化推荐，以及网红推荐（如何将网红推给对应人群，这是我们需要去实现的）

简而言之：推荐系统就是用已有的连接去预测未来用户和物品之间会出现的连接。（这里的物品也可以表示人）

# 是否需要推荐系统？

1. 产品的目的不在于建立连接，例如工具类产品。
2. 产品目前的体量，如果产品中的物品很少，那么采用人工推荐可能是更好的选择。

组建一套推荐系统，需要不小的前期投入，包括组建团队，购置计算资源，积累数据，花费时间优化，当系统体量较小时，我们更需要考虑的是用户增长问题。有一个判断标准，$\triangle connection/(\triangle user *\triangle item)$

当该系数扩大的时候，表明我们系统的连接数在发生自增长，那么就可以考虑加入推荐系统。当然这只是数据层面来说，出于其他战略考虑的话，也是可以加入推荐系统。

# 推荐系统的问题模式

## 评分预测

例如一个用户消费完一个物品，会给物品打分。那么评分预测就是把用户可能回答高分的物品推给用户，让用户进行消费。

那么如何去建立模型呢，有一个朴素的方法，就是对用户曾经打分的商品进行打分，然后将预测分值和实际分值进行比较，得出误差，根据误差去调整模型参数，让这个误差越来越小。这就是机器学习里面的回归问题。

对模型的准确率评判使用RMSE，即均方根误差。

$RMSE = \sqrt{\frac{\sum_{i=1}^{n}(y_i - \hat{y_i})^2}{n}}
$

$\hat{y_i}$表示预测分值，$y_i$表示实际分值。

评分预测问题常见于各种点评类产品，例如书影音评分。但是评分类推荐存在以下问题，

1. 数据不易收集，评分往往产生在最后一步，数据量相对较少
2. 数据质量无法保证，用户可能是随手点了个评分，同时人的评分标准不统一

## 行为预测

行为预测与评分不同，用户在APP上会进行大量的行为操作，可以根据这些数据对用户接下来的行为进行预测。

## 常见的问题

推荐系统有几个常见的问题，并没有很好的通用解决方案。

1. 冷启动问题
2. 探索与利用问题
3. 安全问题

**冷启动问题**

推荐系统是数据贪婪型应用，所谓贪婪型应用就是对数据需求是无限大。系统初期，缺乏对应的数据，想让系统启动起来就很困难。

**探索与利用问题（EE问题）**

假设我们已经知道了用户的喜好，一般有三种对待方式：

1. 全部给他推荐感兴趣的物品
2. 无视他的兴趣，按其他逻辑给他推荐，如编辑推荐、随机推荐、按时间先后推荐等等
3. 大部分给他推荐感兴趣的，小部分去试探新的兴趣

第三种方式明显更为科学，那么如何平衡这两个部分，这就是EE问题的核心，Exploit意为开采，explore意为探索。

# 用户画像

## 什么是用户画像

用户画像即User profile，原本用于营销领域，传统营销领域，画像系统会为用户打各种标签，市场销售人员可以根据各种标签对客户定制化服务。

然而推荐系统的用户画像和上述的传统画像有着很大的区别，根本原因就在于我们的用户画像是给机器看，而不是给人看。

首先推荐系统需要将用户和物品向量化，这样才能进行计算。不同的算法，向量化的方式也不同，最终对匹配评分方法也不同。

用户向量化后的结果，即为用户画像，用户画像是构建推荐系统的过程中产生的一个副产品。

另外通常大型推荐系统一般都分为召回和排序两个阶段。由于全量物品数量非常大，无法为一个用户逐一计算每一个物品的评分，这时候就需要召回，即预筛选掉一部分物品，从而降低计算量。最后再根据评分做排序。

## 关键因素

举个简单的例子，例如店铺推荐，我们可以将店铺向量化，暂定向量的维度有：

1. 价格，1~5分，1分最贵
2. 种类，1~5分，1分代表最少
3. 质量，1~5分，1分表示最差

那么我们会对用户也进行上述的评分，如果一个用户不差钱，只看中质量，该用户的向量可能如下所示

> 1:1
>
> 2:3
>
> 3:5

呢么我们可以简单的计算，将每个维度相乘累加，就可以得到每个店铺的分值，根据分值进行排序即可。

从上面这个例子我们可以看出，构建画像，首先要定义维度，其次是对个维度进行量化。

## 构建画像

### 构建方法

主要分为三类构建方法。

**查户口**

直接使用原始数据构建用户画像，如注册资料，人口统计学信息，购买历史，阅读历史等，一般用于冷启动场景。相对而言不需要什么技术含量，主要就是数据清洗，不会对数据做任何抽象和归纳。

**堆数据**

通过统计来堆积历史数据，最常见的就是兴趣标签，从历史的行为数据中挖掘标签，然后在标签维度上做数据统计，用统计结果作为量化结果。

**黑盒**

使用机器学习方法，形成稠密向量，在推荐系统中承担主要作用。

比如使用浅语义模型构建用户阅读兴趣，或者使用矩阵分解得到的隐因子，或者使用深度学习模型学习用户的Embedding向量。

### 从文本构建

文本是互联网中最常见的信息载体，用户拥有姓名，个人签名，评论动态，点赞，聊天记录等等一系列信息可以用于构建用户画像。物品这边有标题描述，各种属性。

当然文本面临的问题在于，数据结构不统一，信息冗余量大等一系列问题，一般来说文本构建画像分为以下两步

1. 文本结构化，提取关键信息
2. 根据用户行为提取出物品结构化结果，将用户信息与物品信息合并

#### **文本结构化**

由于我们的文本数据，一般来说都是自然语言，即非结构化数据。我们需要将这些数据处理成结构化的数据索引，然后进行向量化计算。

可以试用NLP算法分析文本，得到以下数据：

1. 关键词提取：为其他文本分析提供基础数据，常用TF-IDF和TextRank
2. 实体识别：人物、位置和地点、著作影视剧、历史事件和热点事件等，常用基于词典的方法结合CRF模型
3. 内容分类：将文本按照分类体系分类，用分类来表达较粗粒度的结构化信息
4. 文本：无监督学习，将文本划分为多个类簇
5. 主题模型：从大量的已有文本中学习主题向量，然后预测新的文本在各个主题上的概率分布情况，也很实用。
6. 嵌入：嵌入表达用于挖掘字面下的义信息，并且使用有限的维度进行表达

##### TF-IDF

TF全称为Term Frequency，IDF就是Inverse Document Frequency。该算法的思想很简单，主要包括两点：在一篇文字中反复出现的词会更重要，在所有文本中都出现的词更不重要。

TF：关键词在目标文本中出现的次数

IDF：提前统计好，在现有的文本中，每一个词出现在多少个文本中记为n，也就是文档频率，记为n，也就是文档频率，一共有多少文本，记为N，$IDF=log\frac{N}{n+1}$。

对于IDF而言，N是固定的，n越小，IDF越大。为了防止n为0导致的IDF无穷大，我们需要对分母+1。

计算出TF和IDF后，将两值相乘，就得到每一个词的权重，根据权重可以取topk也可以自定义过滤。

##### TextRank

TextRank和PageRank的思路类似。

1. 设定一个窗口宽度，比如取k个词，统计窗口内的词的共现关系，将其看成无向图
2. 所有词初始化的重要性都是1
3. 每个节点把自己的权重平均分给和自己有链接的其他节点
4. 每个节点将其他节点分给自己的权重求和，作为该节点的新权重
5. 反复迭代3、4步，直接节点权重收敛

这样有共现关系的词会互相支持对方成为关键词。

##### 内容分类

在门户网站时代，每个门户都有自己的频道体系，这就是内容分类体系的一种。如今是UGC时代，文本相对都比较短，短文本提取经典的算法是SVM，常见的工具则是Facebook的FastText。

##### 实体识别

命名实体识别（Named-Entity Recognition）是序列标注问题，和分词、词性标注属于同类问题。

序列标注问题，就是给你一个字符序列，从左向右遍历每个字符，并且对每个字符进行分类，分类的体系因序列标注问题不同有所差异。

1. 分词问题：将每一个字符分类为词开始，词中间，词结束。
2. 词性标注：对每一个分好的词，分类为定义的词性集合之一。
3. 实体识别：对每一个分好的词，识别为定义好的实体集合之一

通常的算法就是隐马尔科夫模型HMM或者条件随机场CRF。

非模型算法有：词典法，提前定义好词典，如果在词典中找到这个词，就能找到对应的实体。

常见的工具有spaCy和NLTK。

##### 聚类

传统聚类方法在文本中的运用，今天逐渐被主题模型取代，以LDA为代表的主题模型可以更准确的抓住主题，同时能够得到软聚类的效果，让一条文本属于多个类簇。

LDA难点在于并行化，如果文本数量没有达到海量，可以考虑提高单机配置，开源的LDA训练工具有Gensim，PLDA。

##### 词嵌入

为一个词学习得到一个稠密的向量，例如北京，可以包含首都、中国、北方、直辖市等语义，假设有128个语义，那么我们可以用一个128维向量来表达，各个维度的大小则表示在这个维度上的语义多少。

我们可以通过这个向量

1. 计算词相似度，扩充结构化标签
2. 累加得到一个文本的稠密向量
3. 用于聚类，会得到比使用词向量聚类更好的语义聚类效果

这方面的权威做法就是Word2Vec，通过浅层神经网络学习得到每个词的向量表达，Word2Vec在工程技巧上进行了优化，百万规模再单机上可以轻松地计算出向量。

#### 标签选择

前面我们已经可以将用户和物品的信息进行结构化，那么如何从这些结构化信息中提取中我们想要的信息呢？

一种简单粗暴的办法就是直接把用户产生过行为的物品标签累积在一起。最常见的两个方法就是卡方检验CHI和信息增益IG。

1. 把物品的结构化内容看成文档
2. 把用户对物品的行为看成是类别
3. 每个用户看见过的物品是一个文本集合
4. 在这个文本集合上使用特征选择算法选出每个用户关心的东西

# 内容推荐

内容推荐，实际上就是一个包装成推荐系统的信息检索系统。

抓：抓取数据，丰富自己的内容

洗：清洗数据

挖：挖掘数据

算：匹配用户的兴趣和物品的属性，计算出更合理的相关性

内容推荐，最重要的不是推荐算法，而是内容挖掘和分析。



# 协同过滤

当推荐系统过了基于内容的推荐阶段后，就有了客观的用户行为，这些行为可以表达成一个用户和物品的关系矩阵。

这个用户物品的关系矩阵填充的就是用户对物品的态度，但并不是每个位置都有用，需要的就是把那些还没有的地方填起来。协同过滤就是围绕这个矩阵来进行。

协同过滤一般划分为两类：

1. Memory-Based
2. Model-Based

Memory-Based就是记住每个人消费什么东西，然后推荐相似的东西、或者推荐相似的人消费的东西。

Model-based就是从用户物品矩阵中学习一个模型，从而把矩阵空白给填满。

基于Memory-Based又分为User-based和Item-based。

## User-Based

这个算法的思想很简单，就是给你推荐跟你相似用户的物品。就好比如果一个人之前看的书和你非常相似，那么就可以将这个人看的书推荐给你。这其实就是将用户进行聚类，想通群体之间常常会有很多相同点。

### 原理

**准备用户向量**

这个前提是用户已经在我们的系统中产生了行为数据。

这个向量有三个特点：

1. 维度是物品的个数
2. 向量是稀疏的
3. 向量上的取值可以是0或1，表示购买过和没购买过

**计算相似度**

将每一个用户向量，两两计算，得出相似度，设定一个相似度阈值或者设定一个最大数量，为每个用户保留与其最相似的用户。

**得到结果**

为每个用户产生推荐结果，将他们相似用户的物品汇总，过滤掉已经购买过的商品，就可以输出推荐结果。这个商品汇总的结果可以用这个公式表示：$P_{u,j}=\frac{\sum_{j}^{n}sim_{u,j}*R_{j,i}}{\sum_{j}^{n}sim_{u,j}}$

式子左边表示一个物品i和一个用户u的匹配分数，右边的分母表示用户u相似的n用户的相似度之和，分子表示这n个用户对物品i的态度，按照相似度进行加权求和。

这里的R可能有多种，如果按照喜欢和不喜欢，那么则为0\1，如果是有分值也可以用分值进行计算。

### 实践

原理比较简单，但是实现中会有这么几个问题：

1. 只有原始用户行为日志，如何从中构造出矩阵
2. 如果用户向量很长，如何快速算出向量
3. 用户量很大，如何快速计算用户相似度
4. 计算出相似度，又需要计算每个物品的分数，这个速度理论上很慢

**构造矩阵**

由于基本上都是稀疏矩阵，所以这里讲几种稀疏矩阵的存储方式。

1. CSR：这个存储有点复杂，是一个整体编码的方式。由数值，列号和行偏移共同编码。
2. COO：每个元素用一个三元组表示（行号，列号，数值），缺失值不存储。

**相似度计算**

相似度计算常规来说就是遍历所有维度进行比较，通常降低相似度计算复杂度的方法有两种

1. 采样计算，例如有100维向量，采取其中10维计算相似度计算，Twitter提出的DIMSUM算法就是这种算法。

2. 向量化计算，利用线性代数对向量直接进行计算，例如计算cos值，$[ \cos\theta = \frac{A \cdot B}{|A| |B|} ]$，值越接近1代表二者越相似。

3. 用户量大，两两计算代价较大，如何解决呢。

   第一种是使用Map Reduce，将原始矩阵Map成键为用户对，值为两个用户对一个物品的评分乘积，Reduce阶段对这些乘积求和，最后再对这些值归一化。

   第二种是直接不适用User-Based。

另外，这种计算对象两两之间的相似度的任务，如果数据量不大，一般来说不超过百万个，然后矩阵又是稀疏的，那么有很多单机版本的⼯具其实更快，⽐如 KGraph、 GraphCHI 等。

**推荐计算**

得到相似用户后，还需要计算推荐分数。显然，为每一个用户计算每一个物品的推荐分数，计算次数是矩阵所有元素个数，这个代价太大，但是我们可以简化这个过程。

1. 只有相似用户喜欢过的物品需要计算
2. 把计算过程拆成Map Reduce任务
   1. 遍历每个用户喜欢的物品列表
   2. 获取该用户的相似用户列表
   3. 将喜欢的物品Map成两个记录发出去，一个键为<相用户id，物品id，1>，值为相似度，另一个是键为<相似用户id，物品id，0>，值为<喜欢程度*相似度>，0和1用于区分两类数据
   4. reduce阶段，求和后输出，<相似用户id，物品id，0>/<相似用户id，物品id，1>的值

MapReduce不一定非要用分布式实现，也可以使用OpenMP单机多线程去做。

**改进**

1. 惩罚热门物品的喜欢程度，这是因为热门的东西很难反映出用户的真实兴趣，更可能是被煽动的群体行为
2. 增加喜欢程度的时间衰减，一般使用一个指数函数，值和喜欢行为发生时间间隔正相关即可。

### 应用场景

协同过滤有两个产出

1. 相似用户列表
2. 基于用户的推荐结果

所以我们可以不仅可以推荐物品，也可以推荐相似的人。

## Item-Based

Item-Bsaed诞生于1998年，由亚马逊率先提出，并在2001发表了相关论文。

### 原理

User-Based有以下几个问题：

1. 用户数量大，计算非常吃力
2. 用户的口味变化快，兴趣迁移问题很难反馈出来
3. 数据稀疏，用户和用户之间的共同消费行为实际上比较少，一般都是热门物品，对发现用户兴趣帮助不大

相较于User-Based，Item-Based是计算相似物品，再根据用户曾经消费过的物品进行推荐。

物品的数量往往少于用户数量，且物品之间的相似度比较静态，变化比较慢。

**基本步骤**

1. 构建用户物品关系矩阵，矩阵元素可以是用户的消费行为，也可以是消费后的评价，还可以是消费行为的某种量化数据，例如时间，次数，费用等
2. 对物品进行计算，得出物品相似度矩阵
3. 产生推荐结果，结果一般有两种形式，第一种是猜你喜欢，第二种是相关物品推荐

**计算物品相似度**

物品关系矩阵得到的物品向量长什么样呢

1. 是一个稀疏向量
2. 向量的维度使用户，一个用户代表向量的一维，这个向量的总共维度是总用户数量
3. 向量各个维度的取值表示用户对该物品的消费结果，这个值可以是布尔值，也可以通过消费行为量化如时间长短，次数多少，费用大小等，也可以是消费评分

物品相似度计算，一般选择余弦相似度。

物品之间的相似度计算是这个算法可以改进的地方，通常有两种

1. 物品中心化。把矩阵中的分数，减去物品分数的均值，先计算每一个物品收到评分的均值，然后再把物品向量中的分数减去对应物品的均值。这样做的目的可以排除掉物品中脑残粉集体打高分的影响。
2. 用户中心化。把矩阵中的分数，减去对应用户分数的均值；先计算每一个用户的评分均质，然后将每一个用户打过的分数都减去它的分数均值。

**计算推荐结果**

